<!DOCTYPE html PUBLIC "-//W3C//DTD HTML 4.01//EN"
   "http://www.w3.org/TR/html4/strict.dtd">
<!--
generated by Pygments <https://pygments.org/>
Copyright 2006-2025 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
-->
<html>
<head>
  <title></title>
  <meta http-equiv="content-type" content="text/html; charset=None">
  <style type="text/css">
/*
generated by Pygments <https://pygments.org/>
Copyright 2006-2025 by the Pygments team.
Licensed under the BSD license, see LICENSE for details.
*/
pre { line-height: 125%; }
td.linenos .normal { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
span.linenos { color: inherit; background-color: transparent; padding-left: 5px; padding-right: 5px; }
td.linenos .special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
span.linenos.special { color: #000000; background-color: #ffffc0; padding-left: 5px; padding-right: 5px; }
body .hll { background-color: #ffffcc }
body { background: #f8f8f8; }
body .c { color: #3D7B7B; font-style: italic } /* Comment */
body .err { border: 1px solid #F00 } /* Error */
body .k { color: #008000; font-weight: bold } /* Keyword */
body .o { color: #666 } /* Operator */
body .ch { color: #3D7B7B; font-style: italic } /* Comment.Hashbang */
body .cm { color: #3D7B7B; font-style: italic } /* Comment.Multiline */
body .cp { color: #9C6500 } /* Comment.Preproc */
body .cpf { color: #3D7B7B; font-style: italic } /* Comment.PreprocFile */
body .c1 { color: #3D7B7B; font-style: italic } /* Comment.Single */
body .cs { color: #3D7B7B; font-style: italic } /* Comment.Special */
body .gd { color: #A00000 } /* Generic.Deleted */
body .ge { font-style: italic } /* Generic.Emph */
body .ges { font-weight: bold; font-style: italic } /* Generic.EmphStrong */
body .gr { color: #E40000 } /* Generic.Error */
body .gh { color: #000080; font-weight: bold } /* Generic.Heading */
body .gi { color: #008400 } /* Generic.Inserted */
body .go { color: #717171 } /* Generic.Output */
body .gp { color: #000080; font-weight: bold } /* Generic.Prompt */
body .gs { font-weight: bold } /* Generic.Strong */
body .gu { color: #800080; font-weight: bold } /* Generic.Subheading */
body .gt { color: #04D } /* Generic.Traceback */
body .kc { color: #008000; font-weight: bold } /* Keyword.Constant */
body .kd { color: #008000; font-weight: bold } /* Keyword.Declaration */
body .kn { color: #008000; font-weight: bold } /* Keyword.Namespace */
body .kp { color: #008000 } /* Keyword.Pseudo */
body .kr { color: #008000; font-weight: bold } /* Keyword.Reserved */
body .kt { color: #B00040 } /* Keyword.Type */
body .m { color: #666 } /* Literal.Number */
body .s { color: #BA2121 } /* Literal.String */
body .na { color: #687822 } /* Name.Attribute */
body .nb { color: #008000 } /* Name.Builtin */
body .nc { color: #00F; font-weight: bold } /* Name.Class */
body .no { color: #800 } /* Name.Constant */
body .nd { color: #A2F } /* Name.Decorator */
body .ni { color: #717171; font-weight: bold } /* Name.Entity */
body .ne { color: #CB3F38; font-weight: bold } /* Name.Exception */
body .nf { color: #00F } /* Name.Function */
body .nl { color: #767600 } /* Name.Label */
body .nn { color: #00F; font-weight: bold } /* Name.Namespace */
body .nt { color: #008000; font-weight: bold } /* Name.Tag */
body .nv { color: #19177C } /* Name.Variable */
body .ow { color: #A2F; font-weight: bold } /* Operator.Word */
body .w { color: #BBB } /* Text.Whitespace */
body .mb { color: #666 } /* Literal.Number.Bin */
body .mf { color: #666 } /* Literal.Number.Float */
body .mh { color: #666 } /* Literal.Number.Hex */
body .mi { color: #666 } /* Literal.Number.Integer */
body .mo { color: #666 } /* Literal.Number.Oct */
body .sa { color: #BA2121 } /* Literal.String.Affix */
body .sb { color: #BA2121 } /* Literal.String.Backtick */
body .sc { color: #BA2121 } /* Literal.String.Char */
body .dl { color: #BA2121 } /* Literal.String.Delimiter */
body .sd { color: #BA2121; font-style: italic } /* Literal.String.Doc */
body .s2 { color: #BA2121 } /* Literal.String.Double */
body .se { color: #AA5D1F; font-weight: bold } /* Literal.String.Escape */
body .sh { color: #BA2121 } /* Literal.String.Heredoc */
body .si { color: #A45A77; font-weight: bold } /* Literal.String.Interpol */
body .sx { color: #008000 } /* Literal.String.Other */
body .sr { color: #A45A77 } /* Literal.String.Regex */
body .s1 { color: #BA2121 } /* Literal.String.Single */
body .ss { color: #19177C } /* Literal.String.Symbol */
body .bp { color: #008000 } /* Name.Builtin.Pseudo */
body .fm { color: #00F } /* Name.Function.Magic */
body .vc { color: #19177C } /* Name.Variable.Class */
body .vg { color: #19177C } /* Name.Variable.Global */
body .vi { color: #19177C } /* Name.Variable.Instance */
body .vm { color: #19177C } /* Name.Variable.Magic */
body .il { color: #666 } /* Literal.Number.Integer.Long */

  </style>
</head>
<body>
<h2></h2>

<div class="highlight"><table class="highlighttable"><tr><td class="linenos"><div class="linenodiv"><pre><span class="normal">  1</span>
<span class="normal">  2</span>
<span class="normal">  3</span>
<span class="normal">  4</span>
<span class="normal">  5</span>
<span class="normal">  6</span>
<span class="normal">  7</span>
<span class="normal">  8</span>
<span class="normal">  9</span>
<span class="normal"> 10</span>
<span class="normal"> 11</span>
<span class="normal"> 12</span>
<span class="normal"> 13</span>
<span class="normal"> 14</span>
<span class="normal"> 15</span>
<span class="normal"> 16</span>
<span class="normal"> 17</span>
<span class="normal"> 18</span>
<span class="normal"> 19</span>
<span class="normal"> 20</span>
<span class="normal"> 21</span>
<span class="normal"> 22</span>
<span class="normal"> 23</span>
<span class="normal"> 24</span>
<span class="normal"> 25</span>
<span class="normal"> 26</span>
<span class="normal"> 27</span>
<span class="normal"> 28</span>
<span class="normal"> 29</span>
<span class="normal"> 30</span>
<span class="normal"> 31</span>
<span class="normal"> 32</span>
<span class="normal"> 33</span>
<span class="normal"> 34</span>
<span class="normal"> 35</span>
<span class="normal"> 36</span>
<span class="normal"> 37</span>
<span class="normal"> 38</span>
<span class="normal"> 39</span>
<span class="normal"> 40</span>
<span class="normal"> 41</span>
<span class="normal"> 42</span>
<span class="normal"> 43</span>
<span class="normal"> 44</span>
<span class="normal"> 45</span>
<span class="normal"> 46</span>
<span class="normal"> 47</span>
<span class="normal"> 48</span>
<span class="normal"> 49</span>
<span class="normal"> 50</span>
<span class="normal"> 51</span>
<span class="normal"> 52</span>
<span class="normal"> 53</span>
<span class="normal"> 54</span>
<span class="normal"> 55</span>
<span class="normal"> 56</span>
<span class="normal"> 57</span>
<span class="normal"> 58</span>
<span class="normal"> 59</span>
<span class="normal"> 60</span>
<span class="normal"> 61</span>
<span class="normal"> 62</span>
<span class="normal"> 63</span>
<span class="normal"> 64</span>
<span class="normal"> 65</span>
<span class="normal"> 66</span>
<span class="normal"> 67</span>
<span class="normal"> 68</span>
<span class="normal"> 69</span>
<span class="normal"> 70</span>
<span class="normal"> 71</span>
<span class="normal"> 72</span>
<span class="normal"> 73</span>
<span class="normal"> 74</span>
<span class="normal"> 75</span>
<span class="normal"> 76</span>
<span class="normal"> 77</span>
<span class="normal"> 78</span>
<span class="normal"> 79</span>
<span class="normal"> 80</span>
<span class="normal"> 81</span>
<span class="normal"> 82</span>
<span class="normal"> 83</span>
<span class="normal"> 84</span>
<span class="normal"> 85</span>
<span class="normal"> 86</span>
<span class="normal"> 87</span>
<span class="normal"> 88</span>
<span class="normal"> 89</span>
<span class="normal"> 90</span>
<span class="normal"> 91</span>
<span class="normal"> 92</span>
<span class="normal"> 93</span>
<span class="normal"> 94</span>
<span class="normal"> 95</span>
<span class="normal"> 96</span>
<span class="normal"> 97</span>
<span class="normal"> 98</span>
<span class="normal"> 99</span>
<span class="normal">100</span>
<span class="normal">101</span>
<span class="normal">102</span>
<span class="normal">103</span>
<span class="normal">104</span>
<span class="normal">105</span>
<span class="normal">106</span>
<span class="normal">107</span>
<span class="normal">108</span>
<span class="normal">109</span>
<span class="normal">110</span>
<span class="normal">111</span>
<span class="normal">112</span>
<span class="normal">113</span>
<span class="normal">114</span>
<span class="normal">115</span>
<span class="normal">116</span>
<span class="normal">117</span>
<span class="normal">118</span>
<span class="normal">119</span>
<span class="normal">120</span>
<span class="normal">121</span>
<span class="normal">122</span>
<span class="normal">123</span>
<span class="normal">124</span>
<span class="normal">125</span>
<span class="normal">126</span>
<span class="normal">127</span>
<span class="normal">128</span>
<span class="normal">129</span>
<span class="normal">130</span>
<span class="normal">131</span>
<span class="normal">132</span>
<span class="normal">133</span>
<span class="normal">134</span>
<span class="normal">135</span>
<span class="normal">136</span>
<span class="normal">137</span>
<span class="normal">138</span>
<span class="normal">139</span>
<span class="normal">140</span>
<span class="normal">141</span>
<span class="normal">142</span>
<span class="normal">143</span>
<span class="normal">144</span>
<span class="normal">145</span>
<span class="normal">146</span>
<span class="normal">147</span>
<span class="normal">148</span>
<span class="normal">149</span>
<span class="normal">150</span>
<span class="normal">151</span>
<span class="normal">152</span>
<span class="normal">153</span>
<span class="normal">154</span>
<span class="normal">155</span>
<span class="normal">156</span>
<span class="normal">157</span>
<span class="normal">158</span>
<span class="normal">159</span>
<span class="normal">160</span>
<span class="normal">161</span>
<span class="normal">162</span>
<span class="normal">163</span>
<span class="normal">164</span>
<span class="normal">165</span>
<span class="normal">166</span>
<span class="normal">167</span>
<span class="normal">168</span>
<span class="normal">169</span>
<span class="normal">170</span>
<span class="normal">171</span>
<span class="normal">172</span>
<span class="normal">173</span>
<span class="normal">174</span>
<span class="normal">175</span>
<span class="normal">176</span>
<span class="normal">177</span>
<span class="normal">178</span>
<span class="normal">179</span>
<span class="normal">180</span>
<span class="normal">181</span>
<span class="normal">182</span>
<span class="normal">183</span>
<span class="normal">184</span>
<span class="normal">185</span>
<span class="normal">186</span>
<span class="normal">187</span>
<span class="normal">188</span>
<span class="normal">189</span>
<span class="normal">190</span>
<span class="normal">191</span>
<span class="normal">192</span>
<span class="normal">193</span>
<span class="normal">194</span>
<span class="normal">195</span>
<span class="normal">196</span>
<span class="normal">197</span>
<span class="normal">198</span>
<span class="normal">199</span>
<span class="normal">200</span>
<span class="normal">201</span>
<span class="normal">202</span>
<span class="normal">203</span>
<span class="normal">204</span>
<span class="normal">205</span>
<span class="normal">206</span>
<span class="normal">207</span>
<span class="normal">208</span>
<span class="normal">209</span>
<span class="normal">210</span>
<span class="normal">211</span>
<span class="normal">212</span>
<span class="normal">213</span>
<span class="normal">214</span>
<span class="normal">215</span>
<span class="normal">216</span>
<span class="normal">217</span>
<span class="normal">218</span>
<span class="normal">219</span>
<span class="normal">220</span>
<span class="normal">221</span>
<span class="normal">222</span>
<span class="normal">223</span>
<span class="normal">224</span>
<span class="normal">225</span>
<span class="normal">226</span>
<span class="normal">227</span>
<span class="normal">228</span>
<span class="normal">229</span>
<span class="normal">230</span>
<span class="normal">231</span>
<span class="normal">232</span>
<span class="normal">233</span>
<span class="normal">234</span>
<span class="normal">235</span>
<span class="normal">236</span>
<span class="normal">237</span>
<span class="normal">238</span>
<span class="normal">239</span>
<span class="normal">240</span>
<span class="normal">241</span>
<span class="normal">242</span>
<span class="normal">243</span>
<span class="normal">244</span>
<span class="normal">245</span>
<span class="normal">246</span>
<span class="normal">247</span>
<span class="normal">248</span>
<span class="normal">249</span>
<span class="normal">250</span>
<span class="normal">251</span>
<span class="normal">252</span>
<span class="normal">253</span>
<span class="normal">254</span>
<span class="normal">255</span>
<span class="normal">256</span>
<span class="normal">257</span>
<span class="normal">258</span>
<span class="normal">259</span>
<span class="normal">260</span>
<span class="normal">261</span>
<span class="normal">262</span>
<span class="normal">263</span>
<span class="normal">264</span>
<span class="normal">265</span>
<span class="normal">266</span>
<span class="normal">267</span>
<span class="normal">268</span>
<span class="normal">269</span>
<span class="normal">270</span>
<span class="normal">271</span>
<span class="normal">272</span>
<span class="normal">273</span>
<span class="normal">274</span>
<span class="normal">275</span>
<span class="normal">276</span>
<span class="normal">277</span>
<span class="normal">278</span>
<span class="normal">279</span>
<span class="normal">280</span>
<span class="normal">281</span>
<span class="normal">282</span>
<span class="normal">283</span>
<span class="normal">284</span>
<span class="normal">285</span>
<span class="normal">286</span>
<span class="normal">287</span>
<span class="normal">288</span>
<span class="normal">289</span>
<span class="normal">290</span>
<span class="normal">291</span>
<span class="normal">292</span>
<span class="normal">293</span>
<span class="normal">294</span>
<span class="normal">295</span>
<span class="normal">296</span>
<span class="normal">297</span>
<span class="normal">298</span>
<span class="normal">299</span>
<span class="normal">300</span>
<span class="normal">301</span>
<span class="normal">302</span>
<span class="normal">303</span>
<span class="normal">304</span>
<span class="normal">305</span>
<span class="normal">306</span>
<span class="normal">307</span>
<span class="normal">308</span>
<span class="normal">309</span>
<span class="normal">310</span>
<span class="normal">311</span>
<span class="normal">312</span>
<span class="normal">313</span>
<span class="normal">314</span>
<span class="normal">315</span>
<span class="normal">316</span>
<span class="normal">317</span>
<span class="normal">318</span>
<span class="normal">319</span>
<span class="normal">320</span>
<span class="normal">321</span>
<span class="normal">322</span>
<span class="normal">323</span>
<span class="normal">324</span>
<span class="normal">325</span>
<span class="normal">326</span>
<span class="normal">327</span>
<span class="normal">328</span>
<span class="normal">329</span>
<span class="normal">330</span>
<span class="normal">331</span>
<span class="normal">332</span>
<span class="normal">333</span>
<span class="normal">334</span>
<span class="normal">335</span>
<span class="normal">336</span>
<span class="normal">337</span>
<span class="normal">338</span>
<span class="normal">339</span>
<span class="normal">340</span>
<span class="normal">341</span>
<span class="normal">342</span>
<span class="normal">343</span>
<span class="normal">344</span>
<span class="normal">345</span>
<span class="normal">346</span>
<span class="normal">347</span>
<span class="normal">348</span>
<span class="normal">349</span>
<span class="normal">350</span>
<span class="normal">351</span>
<span class="normal">352</span>
<span class="normal">353</span>
<span class="normal">354</span>
<span class="normal">355</span>
<span class="normal">356</span>
<span class="normal">357</span>
<span class="normal">358</span>
<span class="normal">359</span>
<span class="normal">360</span>
<span class="normal">361</span>
<span class="normal">362</span>
<span class="normal">363</span>
<span class="normal">364</span>
<span class="normal">365</span>
<span class="normal">366</span>
<span class="normal">367</span>
<span class="normal">368</span>
<span class="normal">369</span>
<span class="normal">370</span>
<span class="normal">371</span>
<span class="normal">372</span>
<span class="normal">373</span>
<span class="normal">374</span>
<span class="normal">375</span>
<span class="normal">376</span>
<span class="normal">377</span>
<span class="normal">378</span>
<span class="normal">379</span>
<span class="normal">380</span>
<span class="normal">381</span>
<span class="normal">382</span>
<span class="normal">383</span>
<span class="normal">384</span>
<span class="normal">385</span>
<span class="normal">386</span>
<span class="normal">387</span>
<span class="normal">388</span>
<span class="normal">389</span>
<span class="normal">390</span>
<span class="normal">391</span>
<span class="normal">392</span>
<span class="normal">393</span>
<span class="normal">394</span>
<span class="normal">395</span>
<span class="normal">396</span>
<span class="normal">397</span>
<span class="normal">398</span>
<span class="normal">399</span>
<span class="normal">400</span>
<span class="normal">401</span>
<span class="normal">402</span>
<span class="normal">403</span>
<span class="normal">404</span>
<span class="normal">405</span>
<span class="normal">406</span>
<span class="normal">407</span>
<span class="normal">408</span>
<span class="normal">409</span>
<span class="normal">410</span>
<span class="normal">411</span>
<span class="normal">412</span>
<span class="normal">413</span>
<span class="normal">414</span>
<span class="normal">415</span>
<span class="normal">416</span>
<span class="normal">417</span>
<span class="normal">418</span>
<span class="normal">419</span>
<span class="normal">420</span>
<span class="normal">421</span>
<span class="normal">422</span>
<span class="normal">423</span>
<span class="normal">424</span>
<span class="normal">425</span>
<span class="normal">426</span>
<span class="normal">427</span>
<span class="normal">428</span>
<span class="normal">429</span>
<span class="normal">430</span>
<span class="normal">431</span>
<span class="normal">432</span>
<span class="normal">433</span>
<span class="normal">434</span>
<span class="normal">435</span>
<span class="normal">436</span>
<span class="normal">437</span>
<span class="normal">438</span>
<span class="normal">439</span>
<span class="normal">440</span>
<span class="normal">441</span>
<span class="normal">442</span>
<span class="normal">443</span>
<span class="normal">444</span>
<span class="normal">445</span>
<span class="normal">446</span>
<span class="normal">447</span>
<span class="normal">448</span>
<span class="normal">449</span>
<span class="normal">450</span>
<span class="normal">451</span>
<span class="normal">452</span>
<span class="normal">453</span>
<span class="normal">454</span>
<span class="normal">455</span>
<span class="normal">456</span>
<span class="normal">457</span>
<span class="normal">458</span>
<span class="normal">459</span>
<span class="normal">460</span>
<span class="normal">461</span>
<span class="normal">462</span>
<span class="normal">463</span>
<span class="normal">464</span>
<span class="normal">465</span>
<span class="normal">466</span>
<span class="normal">467</span>
<span class="normal">468</span>
<span class="normal">469</span>
<span class="normal">470</span>
<span class="normal">471</span>
<span class="normal">472</span>
<span class="normal">473</span>
<span class="normal">474</span>
<span class="normal">475</span>
<span class="normal">476</span>
<span class="normal">477</span>
<span class="normal">478</span>
<span class="normal">479</span>
<span class="normal">480</span>
<span class="normal">481</span>
<span class="normal">482</span>
<span class="normal">483</span>
<span class="normal">484</span>
<span class="normal">485</span>
<span class="normal">486</span>
<span class="normal">487</span>
<span class="normal">488</span>
<span class="normal">489</span>
<span class="normal">490</span>
<span class="normal">491</span>
<span class="normal">492</span>
<span class="normal">493</span></pre></div></td><td class="code"><div><pre><span></span><span class="gh">diff --git a/README.md b/README.md</span>
<span class="gh">index ca94902..d9b0af9 100644</span>
<span class="gd">--- a/README.md</span>
<span class="gi">+++ b/README.md</span>
<span class="gu">@@ -7,7 +7,7 @@ In this assignment, you are required to grasp a known object (power drill). We p</span>
<span class="w"> </span>You can install the environment as follows:
<span class="w"> </span>
<span class="w"> </span>```sh
<span class="gd">-conda create -n hw2 python=3.10</span>
<span class="gi">+conda create -n hw2 python=3.10v</span>
<span class="w"> </span>conda activate hw2
<span class="w"> </span>conda install conda-forge::roboticstoolbox-python==1.0.3
<span class="w"> </span>
<span class="gu">@@ -72,3 +72,4 @@ If you install some packages that are not in the ```Environment``` part, please</span>
<span class="w"> </span>You will get 1% bonus on the final score if you have any model with success rate &gt;= 92.5%
<span class="w"> </span>
<span class="w"> </span>When the point cloud is noisy, you might not be able to fit well if you simply fit using all object points due to the outliers. We can use RANSAC to solve this problem, and you will get 2% bonus on the final score if you implement RANSAC in Part II using only numpy or torch.
<span class="gi">+</span>
<span class="gh">diff --git a/src/config.py b/src/config.py</span>
<span class="gh">index 1aaf852..192cad6 100644</span>
<span class="gd">--- a/src/config.py</span>
<span class="gi">+++ b/src/config.py</span>
<span class="gu">@@ -17,11 +17,11 @@ class Config:</span>
<span class="w"> </span>    &quot;&quot;&quot;the robot we are using&quot;&quot;&quot;
<span class="w"> </span>    obj_name: str = &quot;power_drill&quot;
<span class="w"> </span>    &quot;&quot;&quot;the object we want to grasp&quot;&quot;&quot;
<span class="gd">-    checkpoint: str = None</span>
<span class="gi">+    checkpoint: str = None # &#39;/home/secure/Codes/lzy/eai/Assignment2/exps/est_pose_PointNet_euler_1e-3_64/checkpoint/checkpoint_10000.pth&#39;</span>
<span class="w"> </span>    &quot;&quot;&quot;if not None, then we will continue training from this checkpoint&quot;&quot;&quot;
<span class="gd">-    max_iter: int = 10000</span>
<span class="gi">+    max_iter: int = 20000</span>
<span class="w"> </span>    &quot;&quot;&quot;the maximum number of iterations&quot;&quot;&quot;
<span class="gd">-    batch_size: int = 16</span>
<span class="gi">+    batch_size: int = 64</span>
<span class="w"> </span>    &quot;&quot;&quot;the batch size for training&quot;&quot;&quot;
<span class="w"> </span>    learning_rate: float = 1e-3
<span class="w"> </span>    &quot;&quot;&quot;maximum (and initial) learning rates&quot;&quot;&quot;
<span class="gh">diff --git a/src/model/est_coord.py b/src/model/est_coord.py</span>
<span class="gh">index 0487181..77794bb 100644</span>
<span class="gd">--- a/src/model/est_coord.py</span>
<span class="gi">+++ b/src/model/est_coord.py</span>
<span class="gu">@@ -2,11 +2,13 @@ from typing import Tuple, Dict</span>
<span class="w"> </span>import numpy as np
<span class="w"> </span>import torch
<span class="w"> </span>from torch import nn
<span class="gi">+import torch.nn.functional as F</span>
<span class="w"> </span>
<span class="w"> </span>from ..config import Config
<span class="w"> </span>from ..vis import Vis
<span class="w"> </span>
<span class="w"> </span>
<span class="gi">+</span>
<span class="w"> </span>class EstCoordNet(nn.Module):
<span class="w"> </span>
<span class="w"> </span>    config: Config
<span class="gu">@@ -17,7 +19,24 @@ class EstCoordNet(nn.Module):</span>
<span class="w"> </span>        &quot;&quot;&quot;
<span class="w"> </span>        super().__init__()
<span class="w"> </span>        self.config = config
<span class="gd">-        raise NotImplementedError(&quot;You need to implement some modules here&quot;)</span>
<span class="gi">+</span>
<span class="gi">+        self.mlp1 = nn.Sequential(nn.Linear(3, 64), nn.ReLU())</span>
<span class="gi">+        self.mlp2 = nn.Sequential(nn.Linear(64, 128), nn.ReLU())</span>
<span class="gi">+        self.mlp3 = nn.Sequential(nn.Linear(128, 256), nn.ReLU())</span>
<span class="gi">+        </span>
<span class="gi">+        self.global_fc = nn.Sequential(</span>
<span class="gi">+            nn.Linear(256, 256),</span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Linear(256, 128)</span>
<span class="gi">+        )</span>
<span class="gi">+</span>
<span class="gi">+        self.decoder = nn.Sequential(</span>
<span class="gi">+            nn.Linear(64 + 128 + 128, 128),  </span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Linear(128, 64),</span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Linear(64, 3)</span>
<span class="gi">+        )</span>
<span class="w"> </span>
<span class="w"> </span>    def forward(
<span class="w"> </span>        self, pc: torch.Tensor, coord: torch.Tensor, **kwargs
<span class="gu">@@ -39,13 +58,107 @@ class EstCoordNet(nn.Module):</span>
<span class="w"> </span>        Dict[str, float]
<span class="w"> </span>            A dictionary containing additional metrics you want to log
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        raise NotImplementedError(&quot;You need to implement the forward function&quot;)</span>
<span class="gd">-        loss = ...</span>
<span class="gd">-        metric = dict(</span>
<span class="gd">-            loss=loss,</span>
<span class="gd">-            # additional metrics you want to log</span>
<span class="gd">-        )</span>
<span class="gd">-        return loss, metric</span>
<span class="gi">+        B, N, _ = pc.shape</span>
<span class="gi">+</span>
<span class="gi">+        x1 = self.mlp1(pc)    </span>
<span class="gi">+        x2 = self.mlp2(x1)   </span>
<span class="gi">+        x3 = self.mlp3(x2)     </span>
<span class="gi">+</span>
<span class="gi">+        x_max = torch.max(x3, dim=1, keepdim=True)[0]  </span>
<span class="gi">+        x_global = self.global_fc(x_max)               </span>
<span class="gi">+        x_global_expand = x_global.expand(-1, N, -1)  </span>
<span class="gi">+</span>
<span class="gi">+        x_cat = torch.cat([x1, x2, x_global_expand], dim=-1)  </span>
<span class="gi">+</span>
<span class="gi">+        pred_coord = self.decoder(x_cat) </span>
<span class="gi">+</span>
<span class="gi">+        loss = F.mse_loss(pred_coord, coord)</span>
<span class="gi">+</span>
<span class="gi">+        return loss, {&#39;loss_coord&#39;: loss.item()}</span>
<span class="gi">+    </span>
<span class="gi">+    def umeyama_alignment(self, src: torch.Tensor, tgt: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        src, tgt: shape (B, N, 3)</span>
<span class="gi">+        Returns:</span>
<span class="gi">+            R: (B, 3, 3)</span>
<span class="gi">+            t: (B, 3)</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        B, N, _ = src.shape</span>
<span class="gi">+</span>
<span class="gi">+        mu_src = src.mean(dim=1, keepdim=True) </span>
<span class="gi">+        mu_tgt = tgt.mean(dim=1, keepdim=True) </span>
<span class="gi">+</span>
<span class="gi">+        src_centered = src - mu_src  </span>
<span class="gi">+        tgt_centered = tgt - mu_tgt</span>
<span class="gi">+</span>
<span class="gi">+        cov = torch.matmul(tgt_centered.transpose(1, 2), src_centered) / N </span>
<span class="gi">+</span>
<span class="gi">+        U, S, Vt = torch.linalg.svd(cov)</span>
<span class="gi">+</span>
<span class="gi">+        d = torch.det(torch.matmul(U, Vt))</span>
<span class="gi">+        D = torch.eye(3, device=src.device).unsqueeze(0).repeat(B, 1, 1)</span>
<span class="gi">+        D[:, 2, 2] = torch.where(d &lt; 0, -1.0, 1.0)</span>
<span class="gi">+</span>
<span class="gi">+        R = torch.matmul(torch.matmul(U, D), Vt) </span>
<span class="gi">+        t = mu_tgt.squeeze(1) - torch.matmul(R, mu_src.squeeze(1).unsqueeze(-1)).squeeze(-1) </span>
<span class="gi">+</span>
<span class="gi">+        return R, t</span>
<span class="gi">+</span>
<span class="gi">+    </span>
<span class="gi">+    def ransac_fit(self, pc: torch.Tensor, pred_coord: torch.Tensor, max_iters=100, threshold=0.01):</span>
<span class="gi">+        B, N, _ = pc.shape</span>
<span class="gi">+        device = pc.device</span>
<span class="gi">+        best_R = torch.eye(3, device=device).unsqueeze(0).repeat(B, 1, 1)</span>
<span class="gi">+        best_t = torch.zeros(B, 3, device=device)</span>
<span class="gi">+        best_inlier_count = torch.zeros(B, dtype=torch.long, device=device)</span>
<span class="gi">+</span>
<span class="gi">+        for _ in range(max_iters):</span>
<span class="gi">+            idx = torch.randint(0, N, (B, 3), device=device)  </span>
<span class="gi">+            src = torch.gather(pred_coord, 1, idx.unsqueeze(-1).repeat(1, 1, 3))</span>
<span class="gi">+            tgt = torch.gather(pc, 1, idx.unsqueeze(-1).repeat(1, 1, 3))</span>
<span class="gi">+</span>
<span class="gi">+            R, t = self.umeyama_alignment(src, tgt)</span>
<span class="gi">+</span>
<span class="gi">+            pred_pc = (pred_coord @ R.transpose(1, 2)) + t.unsqueeze(1)</span>
<span class="gi">+            dist = torch.norm(pred_pc - pc, dim=-1) </span>
<span class="gi">+            inlier_mask = (dist &lt; threshold)</span>
<span class="gi">+            inlier_count = inlier_mask.sum(dim=-1)</span>
<span class="gi">+</span>
<span class="gi">+            update_mask = inlier_count &gt; best_inlier_count</span>
<span class="gi">+            best_inlier_count = torch.where(update_mask, inlier_count, best_inlier_count)</span>
<span class="gi">+            best_R = torch.where(update_mask.view(-1, 1, 1), R, best_R)</span>
<span class="gi">+            best_t = torch.where(update_mask.view(-1, 1), t, best_t)</span>
<span class="gi">+</span>
<span class="gi">+        return best_t, best_R</span>
<span class="gi">+    </span>
<span class="gi">+    def forward_coord_only(self, pc: torch.Tensor) -&gt; torch.Tensor:</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        Inference only: given a point cloud, predict corresponding object-frame coordinates.</span>
<span class="gi">+</span>
<span class="gi">+        Parameters</span>
<span class="gi">+        ----------</span>
<span class="gi">+        pc : torch.Tensor</span>
<span class="gi">+            Point cloud in camera frame, shape (B, N, 3)</span>
<span class="gi">+</span>
<span class="gi">+        Returns</span>
<span class="gi">+        -------</span>
<span class="gi">+        torch.Tensor</span>
<span class="gi">+            Predicted coordinates in object frame, shape (B, N, 3)</span>
<span class="gi">+        &quot;&quot;&quot;</span>
<span class="gi">+        B, N, _ = pc.shape</span>
<span class="gi">+</span>
<span class="gi">+        x1 = self.mlp1(pc)    </span>
<span class="gi">+        x2 = self.mlp2(x1)  </span>
<span class="gi">+        x3 = self.mlp3(x2)   </span>
<span class="gi">+</span>
<span class="gi">+        x_max = torch.max(x3, dim=1, keepdim=True)[0] </span>
<span class="gi">+        x_global = self.global_fc(x_max)              </span>
<span class="gi">+        x_global_expand = x_global.expand(-1, N, -1) </span>
<span class="gi">+</span>
<span class="gi">+        x_cat = torch.cat([x1, x2, x_global_expand], dim=-1) </span>
<span class="gi">+        pred_coord = self.decoder(x_cat)                     </span>
<span class="gi">+</span>
<span class="gi">+        return pred_coord</span>
<span class="w"> </span>
<span class="w"> </span>    def est(self, pc: torch.Tensor) -&gt; Tuple[torch.Tensor, torch.Tensor]:
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gu">@@ -71,4 +184,8 @@ class EstCoordNet(nn.Module):</span>
<span class="w"> </span>
<span class="w"> </span>        The only requirement is that the input and output should be torch tensors on the same device and with the same dtype.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        raise NotImplementedError(&quot;You need to implement the est function&quot;)</span>
<span class="gi">+        self.eval()</span>
<span class="gi">+        with torch.no_grad():</span>
<span class="gi">+            pred_coord = self.forward_coord_only(pc)  </span>
<span class="gi">+            trans, rot = self.ransac_fit(pc, pred_coord)</span>
<span class="gi">+        return trans, rot</span>
<span class="gh">diff --git a/src/model/est_pose.py b/src/model/est_pose.py</span>
<span class="gh">index cc55de0..1e55529 100644</span>
<span class="gd">--- a/src/model/est_pose.py</span>
<span class="gi">+++ b/src/model/est_pose.py</span>
<span class="gu">@@ -1,22 +1,56 @@</span>
<span class="w"> </span>from typing import Tuple, Dict
<span class="w"> </span>import torch
<span class="w"> </span>from torch import nn
<span class="gi">+import torch.nn.functional as F</span>
<span class="w"> </span>
<span class="w"> </span>from ..config import Config
<span class="w"> </span>
<span class="gi">+def rotation_6d_to_matrix(d6: torch.Tensor) -&gt; torch.Tensor:</span>
<span class="gi">+    a1 = d6[..., 0:3]</span>
<span class="gi">+    a2 = d6[..., 3:6]</span>
<span class="gi">+</span>
<span class="gi">+    b1 = F.normalize(a1, dim=-1)</span>
<span class="gi">+    b2 = F.normalize(a2 - (b1 * a2).sum(-1, keepdim=True) * b1, dim=-1)</span>
<span class="gi">+    b3 = torch.cross(b1, b2, dim=-1)</span>
<span class="gi">+</span>
<span class="gi">+    return torch.stack((b1, b2, b3), dim=-2)</span>
<span class="gi">+</span>
<span class="gi">+def geodesic_loss(R_pred: torch.Tensor, R_gt: torch.Tensor) -&gt; torch.Tensor:</span>
<span class="gi">+    # Input: Bx3x3 rotation matrices</span>
<span class="gi">+    R_diff = torch.matmul(R_pred.transpose(-1, -2), R_gt)</span>
<span class="gi">+    trace = R_diff[..., 0, 0] + R_diff[..., 1, 1] + R_diff[..., 2, 2]</span>
<span class="gi">+    cos_theta = (trace - 1) / 2</span>
<span class="gi">+    cos_theta = torch.clamp(cos_theta, -1.0 + 1e-6, 1.0 - 1e-6)</span>
<span class="gi">+    theta = torch.acos(cos_theta)</span>
<span class="gi">+    return theta.mean()</span>
<span class="w"> </span>
<span class="w"> </span>class EstPoseNet(nn.Module):
<span class="w"> </span>
<span class="w"> </span>    config: Config
<span class="w"> </span>
<span class="w"> </span>    def __init__(self, config: Config):
<span class="gd">-        &quot;&quot;&quot;</span>
<span class="gd">-        Directly estimate the translation vector and rotation matrix.</span>
<span class="gd">-        &quot;&quot;&quot;</span>
<span class="w"> </span>        super().__init__()
<span class="w"> </span>        self.config = config
<span class="gd">-        raise NotImplementedError(&quot;You need to implement some modules here&quot;)</span>
<span class="gd">-</span>
<span class="gi">+        self.feat = nn.Sequential( </span>
<span class="gi">+            nn.Conv1d(3, 64, 1),</span>
<span class="gi">+            nn.BatchNorm1d(64),</span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Conv1d(64, 128, 1),</span>
<span class="gi">+            nn.BatchNorm1d(128),</span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Conv1d(128, 1024, 1),</span>
<span class="gi">+            nn.BatchNorm1d(1024),</span>
<span class="gi">+            nn.ReLU()</span>
<span class="gi">+        )</span>
<span class="gi">+        self.fc = nn.Sequential(</span>
<span class="gi">+            nn.Linear(1024, 512),</span>
<span class="gi">+            nn.ReLU(),</span>
<span class="gi">+            nn.Linear(512, 256),</span>
<span class="gi">+            nn.ReLU()</span>
<span class="gi">+        )</span>
<span class="gi">+        self.trans_head = nn.Linear(256, 3) </span>
<span class="gi">+        self.rot6d_head = nn.Linear(256, 6) </span>
<span class="gi">+        </span>
<span class="w"> </span>    def forward(
<span class="w"> </span>        self, pc: torch.Tensor, trans: torch.Tensor, rot: torch.Tensor, **kwargs
<span class="w"> </span>    ) -&gt; Tuple[float, Dict[str, float]]:
<span class="gu">@@ -39,11 +73,24 @@ class EstPoseNet(nn.Module):</span>
<span class="w"> </span>        Dict[str, float]
<span class="w"> </span>            A dictionary containing additional metrics you want to log
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        raise NotImplementedError(&quot;You need to implement the forward function&quot;)</span>
<span class="gd">-        loss = ...</span>
<span class="gi">+        pc = pc.transpose(1, 2)</span>
<span class="gi">+        feat = self.feat(pc)  </span>
<span class="gi">+        global_feat = torch.max(feat, 2)[0]  </span>
<span class="gi">+        x = self.fc(global_feat) </span>
<span class="gi">+</span>
<span class="gi">+        pred_trans = self.trans_head(x)  </span>
<span class="gi">+        pred_rot6d = self.rot6d_head(x)  </span>
<span class="gi">+        pred_rot = rotation_6d_to_matrix(pred_rot6d)  </span>
<span class="gi">+</span>
<span class="gi">+        loss_trans = F.mse_loss(pred_trans, trans)</span>
<span class="gi">+        loss_rot = geodesic_loss(pred_rot, rot)</span>
<span class="gi">+</span>
<span class="gi">+        loss = loss_trans + loss_rot</span>
<span class="gi">+</span>
<span class="w"> </span>        metric = dict(
<span class="gd">-            loss=loss,</span>
<span class="gd">-            # additional metrics you want to log</span>
<span class="gi">+            loss=loss.item(),</span>
<span class="gi">+            loss_trans=loss_trans.item(),</span>
<span class="gi">+            loss_rot=loss_rot.item()</span>
<span class="w"> </span>        )
<span class="w"> </span>        return loss, metric
<span class="w"> </span>
<span class="gu">@@ -67,4 +114,14 @@ class EstPoseNet(nn.Module):</span>
<span class="w"> </span>        ----
<span class="w"> </span>        The rotation matrix should satisfy the requirement of orthogonality and determinant 1.
<span class="w"> </span>        &quot;&quot;&quot;
<span class="gd">-        raise NotImplementedError(&quot;You need to implement the est function&quot;)</span>
<span class="gi">+        pc = pc.transpose(1, 2)</span>
<span class="gi">+        feat = self.feat(pc)  </span>
<span class="gi">+        global_feat = torch.max(feat, 2)[0] </span>
<span class="gi">+        x = self.fc(global_feat) </span>
<span class="gi">+</span>
<span class="gi">+        pred_trans = self.trans_head(x)  </span>
<span class="gi">+        pred_rot6d = self.rot6d_head(x)  </span>
<span class="gi">+        pred_rot = rotation_6d_to_matrix(pred_rot6d) </span>
<span class="gi">+</span>
<span class="gi">+        return pred_trans, pred_rot</span>
<span class="gi">+    </span>
\ No newline at end of file
<span class="gh">diff --git a/src/utils.py b/src/utils.py</span>
<span class="gh">index c4d3bf3..944ca4e 100644</span>
<span class="gd">--- a/src/utils.py</span>
<span class="gi">+++ b/src/utils.py</span>
<span class="gu">@@ -81,7 +81,25 @@ def transform_grasp_pose(</span>
<span class="w"> </span>    Grasp
<span class="w"> </span>        The transformed grasp in the robot frame.
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gd">-    raise NotImplementedError</span>
<span class="gi">+    # Step 1: 物体坐标系 → 相机坐标系</span>
<span class="gi">+    # 平移: 先旋转再平移 (T_cam = R_obj2cam @ T_obj + t_obj2cam)</span>
<span class="gi">+    grasp_trans_cam = est_rot @ grasp.trans + est_trans</span>
<span class="gi">+    # 旋转: 直接矩阵相乘 (R_cam = R_obj2cam @ R_obj)</span>
<span class="gi">+    grasp_rot_cam = est_rot @ grasp.rot</span>
<span class="gi">+</span>
<span class="gi">+    # Step 2: 相机坐标系 → 机器人坐标系</span>
<span class="gi">+    # 平移: 先旋转再平移 (T_robot = R_cam2robot @ T_cam + t_cam2robot)</span>
<span class="gi">+    grasp_trans_robot = cam_rot @ grasp_trans_cam + cam_trans</span>
<span class="gi">+    # 旋转: 直接矩阵相乘 (R_robot = R_cam2robot @ R_cam)</span>
<span class="gi">+    grasp_rot_robot = cam_rot @ grasp_rot_cam</span>
<span class="gi">+</span>
<span class="gi">+    # 返回新的 Grasp 对象（夹爪宽度不变）</span>
<span class="gi">+    return Grasp(</span>
<span class="gi">+        trans=grasp_trans_robot,</span>
<span class="gi">+        rot=grasp_rot_robot,</span>
<span class="gi">+        width=grasp.width,</span>
<span class="gi">+    )</span>
<span class="gi">+</span>
<span class="w"> </span>
<span class="w"> </span>def get_pc(depth: np.ndarray, intrinsics: np.ndarray) -&gt; np.ndarray:
<span class="w"> </span>    &quot;&quot;&quot;
<span class="gh">diff --git a/test.sh b/test.sh</span>
<span class="gh">index 9e505df..9fa81fb 100644</span>
<span class="gd">--- a/test.sh</span>
<span class="gi">+++ b/test.sh</span>
<span class="gu">@@ -5,9 +5,11 @@ export WANDB_API_KEY=5bdc90c568050775a6d10650e64857fbbc76742e</span>
<span class="w"> </span>export WANDB_USER_EMAIL=liumail2023@126.com
<span class="w"> </span>export WANDB_USERNAME=liumail2023
<span class="w"> </span>
<span class="gd">-CKPT_PATH=&quot;&quot;</span>
<span class="gi">+CKPT_PATH=&quot;/home/secure/Codes/lzy/eai/Assignment2/exps/est_pose_PointNet_euler_1e-3_64/checkpoint/checkpoint_17500.pth&quot;</span>
<span class="w"> </span>
<span class="w"> </span>python test.py \
<span class="w"> </span>    --checkpoint ${CKPT_PATH} \
<span class="w"> </span>    --mode val \
<span class="gd">-    --device cuda:2</span>
\ No newline at end of file
<span class="gi">+    --device cuda:3</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gh">diff --git a/train.py b/train.py</span>
<span class="gh">index 6f3f365..38e5f70 100644</span>
<span class="gd">--- a/train.py</span>
<span class="gi">+++ b/train.py</span>
<span class="gu">@@ -90,10 +90,12 @@ def main():</span>
<span class="w"> </span>    scheduler = CosineAnnealingLR(
<span class="w"> </span>        optimizer, config.max_iter, eta_min=config.learning_rate_min
<span class="w"> </span>    )
<span class="gi">+    </span>
<span class="gi">+    model.to(device)</span>
<span class="w"> </span>
<span class="w"> </span>    # load checkpoint if exists
<span class="w"> </span>    if config.checkpoint is not None:
<span class="gd">-        checkpoint = torch.load(config.checkpoint, map_location=&quot;cpu&quot;)</span>
<span class="gi">+        checkpoint = torch.load(config.checkpoint, map_location=device)</span>
<span class="w"> </span>        model.load_state_dict(checkpoint[&quot;model&quot;])
<span class="w"> </span>        optimizer.load_state_dict(checkpoint[&quot;optimizer&quot;])
<span class="w"> </span>        cur_iter = checkpoint[&quot;iter&quot;]
<span class="gu">@@ -104,7 +106,7 @@ def main():</span>
<span class="w"> </span>        cur_iter = 0
<span class="w"> </span>
<span class="w"> </span>    # init training
<span class="gd">-    model.to(device)</span>
<span class="gi">+    </span>
<span class="w"> </span>    model.train()
<span class="w"> </span>
<span class="w"> </span>    # start training loop here
<span class="gu">@@ -146,7 +148,10 @@ def main():</span>
<span class="w"> </span>                    result_dicts.append(result_dict)
<span class="w"> </span>                logger.log(
<span class="w"> </span>                    {
<span class="gd">-                        k: np.array([dic[k].cpu() for dic in result_dicts]).mean()</span>
<span class="gi">+                        k: np.array([</span>
<span class="gi">+                            dic[k].cpu() if isinstance(dic[k], torch.Tensor) else dic[k]</span>
<span class="gi">+                            for dic in result_dicts</span>
<span class="gi">+                        ]).mean()</span>
<span class="w"> </span>                        for k in result_dicts[0].keys()
<span class="w"> </span>                    },
<span class="w"> </span>                    &quot;val&quot;,
<span class="gh">diff --git a/train.sh b/train.sh</span>
deleted file mode 100644
<span class="gh">index 96865b9..0000000</span>
<span class="gd">--- a/train.sh</span>
<span class="gi">+++ /dev/null</span>
<span class="gu">@@ -1,14 +0,0 @@</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-</span>
<span class="gd">-export WANDB_API_KEY=5bdc90c568050775a6d10650e64857fbbc76742e</span>
<span class="gd">-export WANDB_USER_EMAIL=liumail2023@126.com</span>
<span class="gd">-export WANDB_USERNAME=liumail2023</span>
<span class="gd">-</span>
<span class="gd">-MODEL_TYPE=est_pose # &#39;est_pose&#39; &#39;est_coord&#39;</span>
<span class="gd">-EXP_NAME=est_pose_test</span>
<span class="gd">-</span>
<span class="gd">-python train.py \</span>
<span class="gd">-    --model_type ${MODEL_TYPE} \</span>
<span class="gd">-    --exp_name ${EXP_NAME} \</span>
<span class="gd">-    --device cuda:2</span>
\ No newline at end of file

<span class="gh">diff --git a/eval.sh b/eval.sh</span>
new file mode 100644
<span class="gh">index 0000000..0000000</span>
<span class="gd">--- /dev/null</span>
<span class="gi">+++ b/eval.sh</span>
<span class="gu">@@ -0,0 +1,18 @@</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+export WANDB_API_KEY=5bdc90c568050775a6d10650e64857fbbc76742e</span>
<span class="gi">+export WANDB_USER_EMAIL=liumail2023@126.com</span>
<span class="gi">+export WANDB_USERNAME=liumail2023</span>
<span class="gi">+# unset VSCODE_IPC_HOOK</span>
<span class="gi">+Xvfb :0 -screen 0 1024x768x24 &amp;</span>
<span class="gi">+export DISPLAY=:0</span>
<span class="gi">+</span>
<span class="gi">+CKPT_PATH=&quot;/home/secure/Codes/lzy/eai/Assignment2/exps/est_pose_PointNet_euler_1e-3_64/checkpoint/checkpoint_15000.pth&quot;</span>
<span class="gi">+</span>
<span class="gi">+python eval.py \</span>
<span class="gi">+    --checkpoint ${CKPT_PATH} \</span>
<span class="gi">+    --mode val \</span>
<span class="gi">+    --device cuda:1 \</span>
<span class="gi">+    --vis=0 \</span>
<span class="gi">+    --headless=1</span>
<span class="gh">diff --git a/train_part1.sh b/train_part1.sh</span>
new file mode 100644
<span class="gh">index 0000000..0000000</span>
<span class="gd">--- /dev/null</span>
<span class="gi">+++ b/train_part1.sh</span>
<span class="gu">@@ -0,0 +1,14 @@</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+export WANDB_API_KEY=5bdc90c568050775a6d10650e64857fbbc76742e</span>
<span class="gi">+export WANDB_USER_EMAIL=liumail2023@126.com</span>
<span class="gi">+export WANDB_USERNAME=liumail2023</span>
<span class="gi">+</span>
<span class="gi">+MODEL_TYPE=est_pose # &#39;est_pose&#39; &#39;est_coord&#39;</span>
<span class="gi">+EXP_NAME=est_pose_PointNet_euler_geodesic_1e-3_64</span>
<span class="gi">+</span>
<span class="gi">+python train.py \</span>
<span class="gi">+    --model_type ${MODEL_TYPE} \</span>
<span class="gi">+    --exp_name ${EXP_NAME} \</span>
<span class="gi">+    --device cuda:3</span>
<span class="gh">diff --git a/train_part2.sh b/train_part2.sh</span>
new file mode 100644
<span class="gh">index 0000000..0000000</span>
<span class="gd">--- /dev/null</span>
<span class="gi">+++ b/train_part2.sh</span>
<span class="gu">@@ -0,0 +1,14 @@</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+</span>
<span class="gi">+export WANDB_API_KEY=5bdc90c568050775a6d10650e64857fbbc76742e</span>
<span class="gi">+export WANDB_USER_EMAIL=liumail2023@126.com</span>
<span class="gi">+export WANDB_USERNAME=liumail2023</span>
<span class="gi">+</span>
<span class="gi">+MODEL_TYPE=est_coord # &#39;est_pose&#39; &#39;est_coord&#39;</span>
<span class="gi">+EXP_NAME=est_coord_PointNet_RANSAC_1e-3_64</span>
<span class="gi">+</span>
<span class="gi">+python train.py \</span>
<span class="gi">+    --model_type ${MODEL_TYPE} \</span>
<span class="gi">+    --exp_name ${EXP_NAME} \</span>
<span class="gi">+    --device cuda:2</span>
</pre></div></td></tr></table></div>
</body>
</html>
